# -*- coding: utf-8 -*-
"""Diabetes_Prediction_Decision_Tree

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZHohfxulWPg-YM6u4t_JUMN_db3Wq5p7

# Diabetes prediction using Decision Tree Algorithm, Worachat Wannawong, Ph.D. 2024

# Dataset

Here's a comprehensive `README.md` file for your `Diabetes_Prediction_Decision_Tree.ipynb` project. This README covers the project overview, requirements, instructions for running the notebook, and references to academic publications that underpin the methods used.

```markdown

# Diabetes Prediction Using Decision Tree

This project demonstrates the use of a Decision Tree Classifier to predict diabetes based on medical diagnostic measurements. It includes data exploration, multiple visualizations, and model evaluation to provide a comprehensive analysis of the dataset.

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Visualizations](#visualizations)
- [Model Evaluation](#model-evaluation)
- [References](#references)

## Overview

The goal of this project is to predict the occurrence of diabetes in patients using a decision tree classifier. The dataset used contains various medical attributes such as glucose level, blood pressure, and age. The project involves data cleaning, visualization, model training, and evaluation.

## Features

- **Data Exploration**: Check for missing values and summarize dataset statistics.
- **Data Visualization**: Scatter plots, histograms, bar plots, boxplots, and correlation heatmaps.
- **Model Training**: Use a Decision Tree Classifier to build the model.
- **Model Evaluation**: Evaluate the model using accuracy, confusion matrix, and classification report.
- **Tree Visualization**: Visual representation of the decision tree.

## Installation

### Prerequisites

- Python 3.6+
- Jupyter Notebook

### Python Libraries

Install the required Python libraries using `pip`:

```bash
pip install pandas matplotlib seaborn scikit-learn
```

## Usage

1. **Clone the Repository**:

   ```bash
   git clone https://github.com/yourusername/diabetes-prediction-decision-tree.git
   cd diabetes-prediction-decision-tree
   ```

2. **Open Jupyter Notebook**:

   ```bash
   jupyter notebook Diabetes_Prediction_Decision_Tree.ipynb
   ```

3. **Run the Notebook**: Execute the cells in the notebook sequentially to load the data, visualize it, and train the model.

## Visualizations

The notebook includes several visualizations to explore and understand the dataset:

1. **Scatter Plot of Pregnancies vs Glucose**:
   ![Scatter Plot](images/scatter_plot_pregnancies_glucose.png)

2. **Histogram of Blood Pressure**:
   ![Histogram](images/histogram_blood_pressure.png)

3. **Bar Plot of Mean Skin Thickness by Outcome**:
   ![Bar Plot](images/bar_plot_skin_thickness_outcome.png)

4. **Boxplot of Age by Outcome**:
   ![Boxplot](images/boxplot_age_outcome.png)

5. **Correlation Heatmap**:
   ![Heatmap](images/correlation_heatmap.png)

6. **Decision Tree Visualization**:
   ![Decision Tree](images/decision_tree.png)

## Model Evaluation

The model's performance is evaluated using:

- **Accuracy**: The percentage of correct predictions.
- **Confusion Matrix**: A table showing the performance of the classifier.
- **Classification Report**: Detailed metrics including precision, recall, and F1-score.

### Example Outputs

- **Accuracy**: `0.77`
- **Confusion Matrix**:
  ```
  [[85 14]
   [21 34]]
  ```
- **Classification Report**:
  ```
               precision    recall  f1-score   support
           0       0.80      0.86      0.83        99
           1       0.71      0.62      0.67        55
    accuracy                           0.77       154
   macro avg       0.76      0.74      0.75       154
weighted avg       0.77      0.77      0.77       154
  ```

## References

The methods and techniques used in this project are based on the following academic publications:

1. **Decision Trees in Machine Learning**
   - Quinlan, J. R. (1986). *Induction of decision trees*. Machine Learning, 1(1), 81-106.
     - **DOI**: [10.1007/BF00116251](https://doi.org/10.1007/BF00116251)

2. **Evaluation Metrics for Classification**
   - Fawcett, T. (2006). *An introduction to ROC analysis*. Pattern Recognition Letters, 27(8), 861-874.
     - **DOI**: [10.1016/j.patrec.2005.10.010](https://doi.org/10.1016/j.patrec.2005.10.010)

3. **Data Visualization in Statistical Analysis**
   - Tufte, E. R. (2001). *The Visual Display of Quantitative Information*. Cheshire, CT: Graphics Press.
     - **ISBN**: 0961392142

4. **Heatmaps for Data Correlation Visualization**
   - Wilkinson, L., & Friendly, M. (2009). *The history of the cluster heat map*. The American Statistician, 63(2), 179-184.
     - **DOI**: [10.1198/tas.2009.0033](https://doi.org/10.1198/tas.2009.0033)

5. **Overview of Machine Learning Techniques for Medical Data**
   - Kourou, K., Exarchos, T. P., Exarchos, K. P., Karamouzis, M. V., & Fotiadis, D. I. (2015). *Machine learning applications in cancer prognosis and prediction*. Computational and Structural Biotechnology Journal, 13, 8-17.
     - **DOI**: [10.1016/j.csbj.2014.11.005](https://doi.org/10.1016/j.csbj.2014.11.005)

---

Feel free to contribute or report any issues. Happy analyzing!
```

### Key Components of the README:

- **Overview**: Brief introduction to the project.
- **Features**: Lists the key functionalities of the notebook.
- **Installation**: Instructions on how to set up the environment.
- **Usage**: Steps to run the notebook.
- **Visualizations**: Descriptions and example images of the visualizations (placeholders for where the actual images should be).
- **Model Evaluation**: Sample outputs for model evaluation metrics.
- **References**: Academic sources supporting the methods used.

This README provides a detailed guide for users to understand, set up, and run your project while giving them insights into the visualizations and model evaluation methods used. Feel free to adjust the content or formatting to better fit your project.



```
# Worachat Wannawong, Ph.D. 2024
```

Worachat Wannawong, Ph.D. 2024: Consistency, Accuracy, and Potential Data Visualization:

**Consistency**

The code appears consistent as it imports pandas twice under different aliases (`pd` and `pd`). This redundancy can be rectified by using the same alias throughout the code.

**Accuracy**

The code seems to be accurate for loading the CSV data into a pandas dataframe (`df`) and transforming the target variable (`Outcome`) into categorical labels (`'No'` and `'Yes'`). It also includes essential imports for data manipulation (`pandas`) and building a decision tree classifier (`DecisionTreeClassifier` from `sklearn.tree`). However, the code snippet stops before training the model or evaluating its accuracy.

**Data Visualization**

Without further context about the features in the 'diabetes.csv' dataset, it's difficult to recommend specific data visualizations. Here are some general approaches that could be useful:

* **Distribution plots:** Create histograms or kernel density estimation (KDE) plots to visualize the distribution of features (e.g., blood sugar levels, age, weight) to identify potential skewness or outliers.
* **Scatter plots:** Explore relationships between features (e.g., blood sugar vs. age) using scatter plots to identify potential correlations.
* **Boxplots:** Use boxplots to compare feature distributions across different categories of the target variable (e.g., 'No' vs. 'Yes' diabetes diagnosis).

**Enhancing the Code**

Here's how you can improve the code:

1. **Remove Redundant Import:**
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

df = pd.read_csv('diabetes.csv')
df
# ... rest of your code



# prompt: การใช้ DataFrame df: Generate the code for multiple plots or Visualizations

import matplotlib.pyplot as plt

# Scatter plot of Pregnancies vs Glucose
plt.scatter(df['Pregnancies'], df['Glucose'])
plt.xlabel('Pregnancies')
plt.ylabel('Glucose')
plt.title('Scatter plot of Pregnancies vs Glucose')
plt.show()

# Histogram of BloodPressure
plt.hist(df['BloodPressure'], bins=10)
plt.xlabel('BloodPressure')
plt.ylabel('Frequency')
plt.title('Histogram of BloodPressure')
plt.show()

# Bar plot of SkinThickness
plt.bar

"""2. **Train-Test Split and Model Evaluation:**"""

X = df.drop('Outcome', axis=1)  # Features
y = df['Outcome']  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = DecisionTreeClassifier()
model.fit(X_train, y_train)
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

"""3. **Data Visualization (Example):**"""

import matplotlib.pyplot as plt
plt.hist(df['BloodPressure'], bins=10, edgecolor='black')
plt.xlabel('Blood Pressure')
plt.ylabel('Frequency')
plt.title('Distribution of Blood Pressure')
plt.show()

"""[ข้อความลิงก์](https://)Remember to replace 'BloodPressure' with the actual feature name from your dataset.

This enhanced code incorporates training-testing for model evaluation and demonstrates a basic data visualization example. You can explore other visualization techniques based on your specific features and analysis goals.
"""

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns

# Load the dataset
df = pd.read_csv('diabetes.csv')

# Display the first few rows of the dataset
df.head()

# Summary statistics
df.describe()

# Check for missing values
df.isnull().sum()

# Scatter plot of Pregnancies vs Glucose
plt.figure(figsize=(10, 6))
plt.scatter(df['Pregnancies'], df['Glucose'], alpha=0.6)
plt.xlabel('Pregnancies')
plt.ylabel('Glucose')
plt.title('Scatter plot of Pregnancies vs Glucose')
plt.show()

# Histogram of BloodPressure
plt.figure(figsize=(10, 6))
plt.hist(df['BloodPressure'], bins=20, edgecolor='black')
plt.xlabel('Blood Pressure')
plt.ylabel('Frequency')
plt.title('Distribution of Blood Pressure')
plt.show()

# Bar plot of the mean SkinThickness by Outcome
plt.figure(figsize=(10, 6))
df.groupby('Outcome')['SkinThickness'].mean().plot(kind='bar', color=['blue', 'orange'])
plt.xlabel('Outcome')
plt.ylabel('Mean Skin Thickness')
plt.title('Mean Skin Thickness by Outcome')
plt.show()

# Boxplot of Age by Outcome
plt.figure(figsize=(10, 6))
sns.boxplot(x='Outcome', y='Age', data=df)
plt.xlabel('Outcome')
plt.ylabel('Age')
plt.title('Boxplot of Age by Outcome')
plt.show()

# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

# Prepare data for modeling
X = df.drop('Outcome', axis=1)  # Features
y = df['Outcome']  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Decision Tree model
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
print(classification_report(y_test, predictions))

# Plot the Decision Tree
plt.figure(figsize=(20, 10))
plot_tree(model, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'], filled=True, rounded=True)
plt.title('Decision Tree')
plt.show()

"""Five academic references to relevant publications.
These references cover machine learning, decision tree classifiers, and data visualization techniques:

References
Decision Trees in Machine Learning

Quinlan, J. R. (1986). Induction of decision trees. Machine Learning, 1(1), 81-106.
DOI: 10.1007/BF00116251
Summary: This seminal paper introduces the concept of decision tree induction, which is foundational for the classifier used in the code.
Evaluation Metrics for Classification

Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874.
DOI: 10.1016/j.patrec.2005.10.010
Summary: Provides a comprehensive overview of Receiver Operating Characteristic (ROC) analysis and related metrics, relevant for evaluating model performance.
Data Visualization in Statistical Analysis

Tufte, E. R. (2001). The Visual Display of Quantitative Information. Cheshire, CT: Graphics Press.
ISBN: 0961392142
Summary: A classic work on data visualization principles, offering insights into how to effectively present quantitative data, applicable to the visualizations in the code.
Heatmaps for Data Correlation Visualization

Wilkinson, L., & Friendly, M. (2009). The history of the cluster heat map. The American Statistician, 63(2), 179-184.
DOI: 10.1198/tas.2009.0033
Summary: Discusses the development and use of heatmaps for displaying data correlations, relevant for the heatmap visualization in the code.
Overview of Machine Learning Techniques for Medical Data

Kourou, K., Exarchos, T. P., Exarchos, K. P., Karamouzis, M. V., & Fotiadis, D. I. (2015). Machine learning applications in cancer prognosis and prediction. Computational and Structural Biotechnology Journal, 13, 8-17.
DOI: 10.1016/j.csbj.2014.11.005
Summary: Reviews the application of various machine learning techniques, including decision trees, in medical data prediction, analogous to the diabetes prediction task.
Formatting References in LaTeX (BibTeX)
For use in LaTeX documents, here are BibTeX entries for the above references:
@article{quinlan1986induction,
  title={Induction of decision trees},
  author={Quinlan, J.R.},
  journal={Machine Learning},
  volume={1},
  number={1},
  pages={81--106},
  year={1986},
  publisher={Springer},
  doi={10.1007/BF00116251}
}

@article{fawcett2006introduction,
  title={An introduction to ROC analysis},
  author={Fawcett, Tom},
  journal={Pattern Recognition Letters},
  volume={27},
  number={8},
  pages={861--874},
  year={2006},
  publisher={Elsevier},
  doi={10.1016/j.patrec.2005.10.010}
}

@book{tufte2001visual,
  title={The Visual Display of Quantitative Information},
  author={Tufte, Edward R.},
  year={2001},
  publisher={Graphics Press},
  address={Cheshire, CT},
  isbn={0961392142}
}

@article{wilkinson2009cluster,
  title={The history of the cluster heat map},
  author={Wilkinson, Leland and Friendly, Michael},
  journal={The American Statistician},
  volume={63},
  number={2},
  pages={179--184},
  year={2009},
  publisher={Taylor \& Francis},
  doi={10.1198/tas.2009.0033}
}

@article{kourou2015machine,
  title={Machine learning applications in cancer prognosis and prediction},
  author={Kourou, Konstantina and Exarchos, Themis P. and Exarchos, Konstantinos P. and Karamouzis, Michalis V. and Fotiadis, Dimitrios I.},
  journal={Computational and Structural Biotechnology Journal},
  volume={13},
  pages={8--17},
  year={2015},
  publisher={Elsevier},
  doi={10.1016/j.csbj.2014.11.005}
}
"""